{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Représentation des symboles en vecteurs numérique\n",
    "\n",
    "Les algorithme de ML & DL ne peuvent pas traité les symboles en tant que telle, nous devons les transformers en vecteur numérique \n",
    "\n",
    "#### Différentes façon de vectoriser des symboles\n",
    "- Vectorisation par la présence et la fréquence des tokens\n",
    "    - Méthode la plus simple et la moins gourmande\n",
    "    - Méthode limité car ne prend pas en compte le contexte et la sémantique de la phrase. On perd les relations entre les mots.\n",
    "- Vectorisation par la contingence des tokens\n",
    "    - Méthode intermédiaire\n",
    "    - Le fait que les tokens sont utilisé au même endroit. Ce n'est pas la méthode de ML la plus perfomante\n",
    "    - Exemple : J'ai un chat à la maison resemble à J'ai un chien à la maison. Il y a donc une contingence entre chat et maison et chien et maison\n",
    "- Vectorisation par apprentissage auto-supervisé\n",
    "    - Méthode la plus compliqué et gourmande\n",
    "    - On va demandé a notre algorithme de ML de prédire les mots dans la phrase. Le modèle va crée un espace vectorielle avec le contexte et le sémantique du texte grace a cette technique\n",
    "    - Exemple: J'ai un chien a la maison , le modèle va prédire le mots après J'ai, puis après un..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "import numpy as np\n",
    "\n",
    "def make_one_hot(label, classes):\n",
    "    vect = np.zeros(len(classes))\n",
    "    if label in classes: vect[classes[label]] = 1\n",
    "    return list(vect)\n",
    "\n",
    "labels = [\n",
    "    'chien', 'chat', 'ours', 'loup', \n",
    "    'chat', 'chat', 'ours', 'chien', \n",
    "    'chien', 'loup', 'ours', 'ours'\n",
    "]\n",
    "\n",
    "classes = {\n",
    "    label: class_index\n",
    "    for class_index, label in enumerate(list(dict.fromkeys(labels).keys()))\n",
    "}\n",
    "\n",
    "one_hot_labels = [make_one_hot(label, classes) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding avec un texte des misérables\n",
    "import numpy as np\n",
    "\n",
    "text = \"\"\"\n",
    "Il jouait on ne sait quel effrayant jeu de cache-cache avec la mort ; \n",
    "chaque fois que la face camarde du spectre s'approchait, le gamin \n",
    "lui donnait une pichenette. Une balle pourtant, mieux ajustée ou \n",
    "plus traître que les autres, finit par atteindre l'enfant feu follet. \n",
    "On vit Gavroche chanceler, puis il s'affaissa.\n",
    "\"\"\"\n",
    "\n",
    "vocab = {\n",
    "    word: vocab_index\n",
    "for vocab_index, word in enumerate(dict.fromkeys(text.split(' ')).keys())}\n",
    "\n",
    "def make_one_hot(label, vocab):\n",
    "    vect = np.zeros(len(vocab))\n",
    "    if label in vocab: vect[vocab[label]] = 1\n",
    "    return list(vect)\n",
    "\n",
    "one_hot_one_liner = lambda label: [1.0 if word == label else 0.0 for word in vocab]\n",
    "\n",
    "print(make_one_hot('Gavroche', vocab))  # On peut voir que plus le texte est grand et plus le One-Hot Encoding est grand \n",
    "                                        # (Une liste de 51 element pour un aussi petit texte)\n",
    "print(one_hot_one_liner('Gavroche'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de la Fréquence d'apparition de symbole\n",
      "[0.01886792 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792\n",
      " 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792 0.03773585\n",
      " 0.01886792 0.01886792 0.01886792 0.01886792 0.03773585 0.01886792\n",
      " 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792\n",
      " 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792\n",
      " 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792\n",
      " 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792\n",
      " 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792 0.01886792\n",
      " 0.01886792 0.01886792 0.01886792]\n"
     ]
    }
   ],
   "source": [
    "# Fréquence d'apparition de symbole\n",
    "\n",
    "text = \"\"\"\n",
    "Il jouait on ne sait quel effrayant jeu de cache-cache avec la mort ; \n",
    "chaque fois que la face camarde du spectre s'approchait, le gamin \n",
    "lui donnait une pichenette. Une balle pourtant, mieux ajustée ou \n",
    "plus traître que les autres, finit par atteindre l'enfant feu follet. \n",
    "On vit Gavroche chanceler, puis il s'affaissa.\n",
    "\"\"\"\n",
    "\n",
    "def vectorize_with_freq(text: str, vocab: list):\n",
    "    words: list[str] = text.split(' ')    \n",
    "    return np.array(\n",
    "        [words.count(word) if word in words else 0 for word in vocab]\n",
    "    ) / len(words)\n",
    "    \"\"\"\n",
    "        Cette liste compréhension est l'équivalent de ce code :\n",
    "        vect = np.zeros(len(vocab))\n",
    "    \n",
    "        for letter in text.lower():\n",
    "            vect[vocab[letter]] += 1\n",
    "            \n",
    "        vect /= len(text)\n",
    "    \"\"\"\n",
    "\n",
    "print(f'Résultat de la Fréquence d\\'apparition de symbole\\n{vectorize_with_freq(text, vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les problèmes de la fréquence d'apparition des symboles\n",
    "- La taille d'un document est égale a celle du vocabulaire\n",
    "- Il ne prend pas en compte la sémantique \n",
    "    - Exemple: \"vent\" et \"vents\" sont considérés commes des labels (features) différente\n",
    "- La fréquence d'apparition ne met pas forcément en valeurs les mots les plus important (\"le\" a une fréquence plus grande que \"Gavroche\" alors qu'il est plus important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fréquence d'apparition de Ngrams\n",
    "\n",
    "Un Ngrams est une suite de tokens de taille n et est généralement couplé à une segmentation plus courte (en charactere par exemple) et permet de contrôler la taille du vocabulaire\n",
    "\n",
    "Cette méthode perd le sens de la phrase mais nous permet de controller la taille des vecteurs, il est en plus possible de combiner des Ngrams de taille X (1, 2, 3, 4 ,5)\n",
    "\n",
    "Mais on se retrouve avec les mêmes problèmes de la fréquence d'apparition des symboles\n",
    "\n",
    "- Il ne prend pas en compte la sémantique \n",
    "    - Exemple: \"vent\" et \"vents\" sont considérés commes des labels (features) différente\n",
    "- La fréquence d'apparition ne met pas forcément en valeurs les mots les plus important "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nI', 'Il', 'l ', ' j', 'jo', 'ou', 'ua', 'ai', 'it', 't ', ' o', 'on', 'n ', ' n', 'ne', 'e ', ' s', 'sa', 'ai', 'it', 't ', ' q', 'qu', 'ue', 'el', 'l ', ' e', 'ef', 'ff', 'fr', 'ra', 'ay', 'ya', 'an', 'nt', 't ', ' j', 'je', 'eu', 'u ', ' d', 'de', 'e ', ' c', 'ca', 'ac', 'ch', 'he', 'e-', '-c', 'ca', 'ac', 'ch', 'he', 'e ', ' a', 'av', 've', 'ec', 'c ', ' l', 'la', 'a ', ' m', 'mo', 'or', 'rt', 't ', ' ;', '; ', ' \\n', '\\nc', 'ch', 'ha', 'aq', 'qu', 'ue', 'e ', ' f', 'fo', 'oi', 'is', 's ', ' q', 'qu', 'ue', 'e ', ' l', 'la', 'a ', ' f', 'fa', 'ac', 'ce', 'e ', ' c', 'ca', 'am', 'ma', 'ar', 'rd', 'de', 'e ', ' d', 'du', 'u ', ' s', 'sp', 'pe', 'ec', 'ct', 'tr', 're', 'e ', ' s', \"s'\", \"'a\", 'ap', 'pp', 'pr', 'ro', 'oc', 'ch', 'ha', 'ai', 'it', 't,', ', ', ' l', 'le', 'e ', ' g', 'ga', 'am', 'mi', 'in', 'n ', ' \\n', '\\nl', 'lu', 'ui', 'i ', ' d', 'do', 'on', 'nn', 'na', 'ai', 'it', 't ', ' u', 'un', 'ne', 'e ', ' p', 'pi', 'ic', 'ch', 'he', 'en', 'ne', 'et', 'tt', 'te', 'e.', '. ', ' U', 'Un', 'ne', 'e ', ' b', 'ba', 'al', 'll', 'le', 'e ', ' p', 'po', 'ou', 'ur', 'rt', 'ta', 'an', 'nt', 't,', ', ', ' m', 'mi', 'ie', 'eu', 'ux', 'x ', ' a', 'aj', 'ju', 'us', 'st', 'té', 'ée', 'e ', ' o', 'ou', 'u ', ' \\n', '\\np', 'pl', 'lu', 'us', 's ', ' t', 'tr', 'ra', 'aî', 'ît', 'tr', 're', 'e ', ' q', 'qu', 'ue', 'e ', ' l', 'le', 'es', 's ', ' a', 'au', 'ut', 'tr', 're', 'es', 's,', ', ', ' f', 'fi', 'in', 'ni', 'it', 't ', ' p', 'pa', 'ar', 'r ', ' a', 'at', 'tt', 'te', 'ei', 'in', 'nd', 'dr', 're', 'e ', ' l', \"l'\", \"'e\", 'en', 'nf', 'fa', 'an', 'nt', 't ', ' f', 'fe', 'eu', 'u ', ' f', 'fo', 'ol', 'll', 'le', 'et', 't.', '. ', ' \\n', '\\nO', 'On', 'n ', ' v', 'vi', 'it', 't ', ' G', 'Ga', 'av', 'vr', 'ro', 'oc', 'ch', 'he', 'e ', ' c', 'ch', 'ha', 'an', 'nc', 'ce', 'el', 'le', 'er', 'r,', ', ', ' p', 'pu', 'ui', 'is', 's ', ' i', 'il', 'l ', ' s', \"s'\", \"'a\", 'af', 'ff', 'fa', 'ai', 'is', 'ss', 'sa', 'a.', '.\\n']\n"
     ]
    }
   ],
   "source": [
    "# Fréquence d'apparition de Ngrams\n",
    "text = \"\"\"\n",
    "Il jouait on ne sait quel effrayant jeu de cache-cache avec la mort ; \n",
    "chaque fois que la face camarde du spectre s'approchait, le gamin \n",
    "lui donnait une pichenette. Une balle pourtant, mieux ajustée ou \n",
    "plus traître que les autres, finit par atteindre l'enfant feu follet. \n",
    "On vit Gavroche chanceler, puis il s'affaissa.\n",
    "\"\"\"\n",
    "\n",
    "ngram_split_one_liner = lambda n: [\n",
    "    word + text[i + j] for i, word in enumerate(text) for j in range(1, n) if not i + n -1 == len(text)\n",
    "]\n",
    "\n",
    "print(ngram_split_one_liner(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
